{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9030884f-2daf-4bf5-abbc-c9366b82d649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"prj-d-bu3machine-learning-ma6i\"\n",
    "REGION = \"us-central1\"\n",
    "BUCKET_URI = \"gs://bkt-d-vertexbucket\"\n",
    "KMS_KEY = \"projects/prj-d-kms-3i3k/locations/us-central1/keyRings/sample-keyring/cryptoKeys/prj-d-bu3machine-learning\"\n",
    "COMPUTE_ENGINE_SA = \"401570045548-compute@developer.gserviceaccount.com\"\n",
    "PEER_NETWORK=\"projects/316945073583/global/networks/vpc-d-shared-restricted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e585f-bb53-495e-80d7-c963a2fb3bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "KFP_COMPONENTS_PATH = \"components\"\n",
    "SRC = \"src\"\n",
    "BUILD = \"build\"\n",
    "Image = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/pipelinerepo/pipeline_tutorial:latest\"\n",
    "\n",
    "#export GOOGLE_APPLICATION_CREDENTIALS = \n",
    "!mkdir -m 777 -p {SRC} {DATA_PATH} {KFP_COMPONENTS_PATH} {BUILD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e77dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile.net\n",
    "FROM {REGION}-docker.pkg.dev/{PROJECT_ID}/pipelinerepo/net-debug\n",
    "RUN pip install kfp==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b92430",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile.gcloud\n",
    "FROM {REGION}-docker.pkg.dev/{PROJECT_ID}/pipelinerepo/net-debug\n",
    "RUN pip install kfp==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "NET_DEBUG_IMAGE=\"{REGION}-docker.pkg.dev/{PROJECT_ID}/pipelinerepo/net-debug\"\n",
    "GCLOUD_IMAGE=\"{REGION}-docker.pkg.dev/{PROJECT_ID}/pipelinerepo/gcloud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a2413",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build . -f ./Dockerfile.net -t \"{NET_DEBUG_IMAGE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5018e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build . -f ./Dockerfile.gcloud -t \"{GCLOUD_IMAGE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo Y | gcloud auth configure-docker {REGION}-docker.pkg.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce47863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push \"{NET_DEBUG_IMAGE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push \"{GCLOUD_IMAGE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c6bc3-d97f-41c8-879c-1edb59a6cfb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install protobuf==3.20.* tensorflow==2.8.0  tensorflow-hub==0.13.0 kfp==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c4447b-b375-4595-82c3-706bd18ee837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path as path\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "from six.moves import urllib\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow_hub as hub\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import GoogleAPIError\n",
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import component\n",
    "from kfp.dsl import Input, Output, Model, Metrics, OutputPath\n",
    "from typing import NamedTuple\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60faba58-e64a-444f-a80a-819af74fa488",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9e2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "        base_image = f\"{GCLOUD_IMAGE}\"\n",
    ")\n",
    "def arbitrary() -> str:\n",
    "    import subprocess\n",
    "    bash_command = \"gcloud config list\"\n",
    "    result = subprocess.run(bash_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    print(\"Command Output:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    if result.stderr:\n",
    "        print(\"Error Output:\")\n",
    "        print(result.stderr)\n",
    "    return \"Finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16338a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "        base_image = f\"{NET_DEBUG_IMAGE}\"\n",
    ")\n",
    "def net() -> str:\n",
    "    import subprocess\n",
    "    bash_command = \"route -n\"\n",
    "    result = subprocess.run(bash_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    print(\"Command Output:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    if result.stderr:\n",
    "        print(\"Error Output:\")\n",
    "        print(result.stderr)\n",
    "    bash_command = \"ifconfig\"\n",
    "    result = subprocess.run(bash_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    print(\"Command Output:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    if result.stderr:\n",
    "        print(\"Error Output:\")\n",
    "        print(result.stderr)\n",
    "    bash_command = \"ping 8.8.8.8\"\n",
    "    result = subprocess.run(bash_command, shell=True, capture_output=True, text=True)\n",
    "\n",
    "    print(\"Command Output:\")\n",
    "    print(result.stdout)\n",
    "\n",
    "    if result.stderr:\n",
    "        print(\"Error Output:\")\n",
    "        print(result.stderr)\n",
    "    return \"Finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfb7d67-49b9-416b-90c1-568648631f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"debug-pipeline\")\n",
    "def pipeline(\n",
    "    create_bq_dataset_query: str,\n",
    "    project: str,\n",
    "    deployment_project: str,\n",
    "    region: str,\n",
    "    model_dir: str,\n",
    "    bucket_name: str,\n",
    "    monitoring_name: str,\n",
    "    monitoring_email: str,\n",
    "    encryption: str,\n",
    "    service_account: str,\n",
    "    train_data_url: str=TRAINING_URL,\n",
    "    eval_data_url: str=EVAL_URL,\n",
    "    bq_dataset: str=DATASET_ID,\n",
    "    bq_train_table: str=TRAINING_TABLE_ID,\n",
    "    bq_eval_table: str=EVAL_TABLE_ID,\n",
    "    job_name: str=JOB_NAME,\n",
    "    requirements_file_path: str=f'{BUCKET_URI}/requirements.txt',\n",
    "    python_file_path: str=f'{BUCKET_URI}/src/ingest_pipeline.py',\n",
    "    dataflow_temp_location: str=f'{BUCKET_URI}/temp_dataflow',\n",
    "    runner: str=RUNNER,                \n",
    "    lr: float=0.01, \n",
    "    epochs: int=5,\n",
    "    batch_size: int=32,\n",
    "    base_train_dir: str=f'{BUCKET_URI}/training', \n",
    "    tb_log_dir: str=f'{BUCKET_URI}/tblogs',\n",
    "    deployment_image: str=\"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-8:latest\",\n",
    "    deployed_model_name: str='income_bracket_predictor',\n",
    "    endpoint_name: str='census_endpoint',\n",
    "    min_nodes: int=2,\n",
    "    max_nodes: int=4,\n",
    "    traffic_split: int=25,\n",
    "):\n",
    "    #arbitrary containers\n",
    "\n",
    "    arb_op = arbitrary()\n",
    "    net_op = net()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777fbce5-34fa-43e8-b1b8-0e95d6f20e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"./common/vertex-ai-pipeline/pipeline_package.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d133e2-a353-45bb-bd5d-f741f626e777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%d_%H_%M_%S\")\n",
    "pipelineroot = f'{BUCKET_URI}/pipelineroot'\n",
    "service_account = COMPUTE_ENGINE_SA\n",
    "#service_account = \"notebook-runner@prj-d-bu3machine-learning-ma6i.iam.gserviceaccount.com\"\n",
    "\n",
    "data_config={\n",
    " \"train_data_url\": TRAINING_URL,\n",
    " \"eval_data_url\": EVAL_URL,\n",
    " \"bq_dataset\": DATASET_ID,\n",
    " \"bq_train_table\": TRAINING_TABLE_ID,\n",
    " \"bq_eval_table\": EVAL_TABLE_ID,\n",
    "}\n",
    "\n",
    "dataflow_config={\n",
    "                \"job_name\": JOB_NAME,\n",
    "                \"requirements_file_path\": f'{BUCKET_URI}/requirements.txt',\n",
    "                \"python_file_path\": f'{BUCKET_URI}/src/ingest_pipeline.py',\n",
    "                \"setup_file_uri\": f'{BUCKET_URI}/setup.py',\n",
    "                \"temp_location\": f'{BUCKET_URI}/temp_dataflow',\n",
    "                \"runner\": RUNNER,\n",
    "}\n",
    "train_config={\n",
    "             'lr': 0.01, \n",
    "             'epochs': 5, \n",
    "             'base_train_dir': f'{BUCKET_URI}/training', \n",
    "             'tb_log_dir': f'{BUCKET_URI}/tblogs',\n",
    "}\n",
    "\n",
    "deployment_config={\n",
    "    'image': \"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-8:latest\",\n",
    "    'model_name': \"income_bracket_predictor\",\n",
    "    'endpoint_name': \"census_income_endpoint\",\n",
    "    'min_nodes': 2,\n",
    "    'max_nodes': 4,\n",
    "    'deployment_project': PROJECT_ID,\n",
    "    \"encryption\": KMS_KEY,\n",
    "    \"service_account\": service_account\n",
    "}\n",
    "\n",
    "monitoring_config={\n",
    "    'email': 'ccolin@clsecteam.com', \n",
    "    'name': 'census_monitoring'  \n",
    "}\n",
    "\n",
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name=f\"census_income_{timestamp}\",\n",
    "    template_path='./common/vertex-ai-pipeline/pipeline_package.yaml',\n",
    "    pipeline_root=pipelineroot,\n",
    "    encryption_spec_key_name=deployment_config.get(\"encryption\"),\n",
    "    parameter_values={\n",
    "        \"create_bq_dataset_query\": create_bq_dataset_query,\n",
    "        \"bq_dataset\": data_config['bq_dataset'],\n",
    "        \"bq_train_table\": data_config['bq_train_table'],\n",
    "        \"bq_eval_table\": data_config['bq_eval_table'],\n",
    "        \"job_name\": dataflow_config['job_name'],\n",
    "        \"train_data_url\": data_config['train_data_url'],\n",
    "        \"eval_data_url\": data_config['eval_data_url'],\n",
    "        \"requirements_file_path\": dataflow_config['requirements_file_path'],\n",
    "        \"python_file_path\": dataflow_config['python_file_path'],\n",
    "        \"dataflow_temp_location\": dataflow_config['temp_location'],\n",
    "        \"runner\": dataflow_config['runner'],\n",
    "        \"project\": PROJECT_ID,\n",
    "        \"region\": REGION,\n",
    "        \"model_dir\": f\"{BUCKET_URI}\",\n",
    "        \"bucket_name\": BUCKET_URI[5:],\n",
    "        \"epochs\": train_config['epochs'],\n",
    "        \"lr\": train_config['lr'],\n",
    "        \"base_train_dir\": train_config['base_train_dir'],\n",
    "        \"tb_log_dir\": train_config['tb_log_dir'],\n",
    "        \"deployment_image\": deployment_config['image'],\n",
    "        \"deployed_model_name\": deployment_config[\"model_name\"],\n",
    "        \"endpoint_name\": deployment_config[\"endpoint_name\"],\n",
    "        \"min_nodes\": deployment_config[\"min_nodes\"],\n",
    "        \"max_nodes\": deployment_config[\"max_nodes\"],\n",
    "        \"deployment_project\": deployment_config[\"deployment_project\"],\n",
    "        \"encryption\": deployment_config.get(\"encryption\"),\n",
    "        \"service_account\": deployment_config[\"service_account\"],\n",
    "        \"monitoring_name\": monitoring_config['name'],\n",
    "        \"monitoring_email\": monitoring_config['email'], \n",
    "        \n",
    "    },\n",
    "    enable_caching=False,\n",
    ")\n",
    "\n",
    "pipeline.submit(network=PEER_NETWORK)\n",
    "#pipeline.run(service_account=service_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3827a-b88c-4110-aa4e-96836472056a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(f\"{BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dc5b11-c9ac-4515-8446-07b30f2a94b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725aab2-18e8-48f8-a3bb-f2ca0210cd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
